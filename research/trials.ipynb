{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c61538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a:\\\\GenAI_Project\\\\First_Nurse\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76188baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8cd407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f3ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chand\\anaconda3\\envs\\medibot\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b554d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from pdf file\n",
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob = \"*.pdf\",\n",
    "        loader_cls = PyPDFLoader\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a107b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6474187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cea1f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of documents, return a new list of Document\n",
    "    objects containing only 'source' in metadata and the original page_conent.\n",
    "    \"\"\"\n",
    "    minimal_docs : List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content = doc.page_content,\n",
    "                metadata = {\"source\" : src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40b96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d496b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the documents into smaller chunks\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap = 20, #to understand the context\n",
    "        length_function = len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(minimal_docs)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2db1162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts: 5859\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Number of texts: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a90e2bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chand\\AppData\\Local\\Temp\\ipykernel_26192\\4087317152.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "#embedding\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name = model_name,\n",
    "        \n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d687147f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4011efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embedding.embed_query(\"am in love with you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a89a4b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8347c7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d17dcbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9629da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9289e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x29f3c1a6320>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58bc7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating database\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension = 384,\n",
    "        metric = \"cosine\",\n",
    "        spec = ServerlessSpec(cloud = \"aws\", region = \"us-east-1\")\n",
    "\n",
    "\n",
    "    )\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db98b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = texts_chunk,\n",
    "    embedding = embedding,\n",
    "    index_name = index_name,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b42208be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOad existing documents\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your pinecone index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name = index_name,\n",
    "    embedding = embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eab600cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make RAG \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280c302",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f38c7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\" : 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "784347c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='22748e44-6726-427c-8fac-2f6d1372ed6b', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='1f873c99-c6fd-458f-af74-c5e6602c83bd', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='6e10f2f4-5219-452b-b499-8bd96f5281ef', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ddd5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#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\n",
    "chatModel = ChatOpenAI(model = \"gpt-4o-mini\",\n",
    "                       openai_api_key= OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6a3ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70667dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an Medical assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f1f60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08055166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is a disorder caused by the abnormal release of a hormone from the pituitary gland, leading to excessive growth of bones and soft tissues, along with various other health disturbances. Gigantism is a related condition that occurs in children, resulting in excessive height and growth due to the same underlying hormone imbalance before the growth plates close. Both conditions are caused by an overproduction of growth hormone.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6af8a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acne is a common skin condition that occurs when hair follicles become blocked with oil and dead skin cells. It often leads to the formation of pimples, blackheads, and cysts, primarily on the face, back, and shoulders. Hormonal changes, bacteria, and certain medications can contribute to its development.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\" : \"what is acne\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82e3ac-a4a7-4092-87c6-1976dba674f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
